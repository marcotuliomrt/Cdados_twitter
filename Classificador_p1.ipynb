{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: _Marco Tulio Masselli Rainho Teixeira_\n",
    "\n",
    "Nome: _Talissa Gonçalves Albertini_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este classificador automático de sentimento tem o objetivo de promover uma otimização no processo de interpretação de feed back de qualquer produto no mercado, identificando características que os usuários aprovam ou reprovam, e no ambiente do Twitter, selecionando comentários que tenham uma maior probabilidade de serem relevantes à equipe que os analizará."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparação do ambiente do Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "from string import punctuation\n",
    "import nltk \n",
    "from nltk.stem import RSLPStemmer\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carregando a base de dados com os tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('xiaomi.xlsx')\n",
    "df1 = pd.read_excel(xls, 'Treinamento')\n",
    "df2 = pd.read_excel(xls, 'Teste')\n",
    "\n",
    "print(df1.head())\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 3. Tratamento do banco de dados de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Remoção de pontuação e uniformização de minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def  Cleanup(df, text_column):\n",
    "    df[text_column] = df[text_column].str.lower()\n",
    "    df[text_column] = df[text_column].str.replace(rf'[{punctuation}]', '')\n",
    "    return df\n",
    "\n",
    "print(Cleanup(df1, 'Treinamento').head(10))\n",
    "print(Cleanup(df2, 'Teste').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Divisão por relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_comments = df1[df1.Relevancia == 1] \n",
    "relevant_comments_column = relevant_comments['Treinamento']\n",
    "relevant_comments_list = relevant_comments_column.values.tolist()\n",
    "print(relevant_comments_list[0:10])\n",
    "\n",
    "irrelevant_comments = df1[df1.Relevancia == 0]\n",
    "irrelevant_comments_column = irrelevant_comments['Treinamento']\n",
    "irrelevant_comments_list = irrelevant_comments_column.values.tolist()\n",
    "#print(irrelevant_comments_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Separação de palávras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_words_raw = [word for comment in relevant_comments_list for word in comment.split()]\n",
    "print(relevant_words_raw[0:30])\n",
    "\n",
    "irrelevant_words_raw = [word for comment in irrelevant_comments_list for word in comment.split()]\n",
    "#print(irrelevant_words_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Remoção de stopwords e stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWords(list_of_words):\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    filtered = []\n",
    "    for word in list_of_words:\n",
    "        if word not in stopwords:\n",
    "            filtered.append(word)\n",
    "    return filtered\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "def Stemming(list_of_words):\n",
    "    stemmer = RSLPStemmer()\n",
    "    filtered = []\n",
    "    for word in list_of_words:\n",
    "        filtered.append(stemmer.stem(word.lower()))\n",
    "    return filtered\n",
    "\n",
    "relevant_words = Stemming(RemoveStopWords(relevant_words_raw))\n",
    "irrelevant_words = Stemming(RemoveStopWords(irrelevant_words_raw))\n",
    "\n",
    "\n",
    "#print(relevant_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Cálculo das frequências relativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_words_serie = pd.Series(relevant_words)\n",
    "relevant_words_relative = relevant_words_serie.value_counts(True)\n",
    "print(relevant_words_relative.head())\n",
    "\n",
    "irrelevant_words_serie = pd.Series(irrelevant_words)\n",
    "irrelevant_words_relative = irrelevant_words_serie.value_counts(True)\n",
    "#print(irrelevant_words_relative.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Espaço amostral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de todas as palávras\n",
    "all_words = relevant_words + irrelevant_words\n",
    "all_words[0:10]\n",
    "\n",
    "# Frequências relativas do total de palávras\n",
    "all_words_serie = pd.Series(all_words)\n",
    "all_words_relative = all_words_serie.value_counts(True)\n",
    "print(all_words_relative.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Descrição das probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eventos\n",
    "\n",
    "* R: Comentário relevante\n",
    "* Rc: Comentário irrelevante\n",
    "* C: Comentário\n",
    "\n",
    "#### Probabilidades\n",
    "\n",
    "* P_R = Probabilidade do comentário ser relevante\n",
    "* P_Rc = Probabilidade do comentario ser irrelevante\n",
    "* P_C = Probabilidade do comentário ocorrer na lingua portugueasa = propabilidade de cada palavra ocorrer na lingua portuguesa, multiplicadas entre si\n",
    "* P_C_dado_R = Probabilidade do comentário ocorrer dado que o é relevante = probabilidade de cada palavra ocorrer dado que o comentário é relevante, multiplicados entre si\n",
    "* P_C_dado_Rc = Probabilidade do comentário ocorrer dado que é irrelevante = probabilidade de cada palavra ocorrer dado que o comentário é irrelevante, multiplicados entre si\n",
    "* P_R_dado_C = Probabilidade do cometário ser relevante dado o comentário\n",
    "* P_Rc_dado_C =Probabilidade do cometário ser irrelevante dado o comentário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Funções auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Função para a suavização de Laplace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Laplace(N_words_X, N_dif_words_X, N_dif_words_Xc):\n",
    "    correction = 1/(len(N_words_X) + len(N_dif_words_X) + len(N_dif_words_Xc))\n",
    "    return correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Função multiplicadora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiplyList(List) : \n",
    "    result = 1\n",
    "    for x in List: \n",
    "         result = result * x  \n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_range = []\n",
    "for row in df2.index: \n",
    "    df2_range.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Função classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['test_result'] = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier(df):\n",
    "    for i in df2_range:\n",
    "        comment = df2.iloc[i, 1]\n",
    "\n",
    "\n",
    "        # Frequencia das palavras do comentario\n",
    "        comment_words = comment.split()\n",
    "        comment_words_list = Stemming(RemoveStopWords(comment_words))\n",
    "        comment_words_serie = pd.Series(comment_words_list)\n",
    "        comment_words_frequency = comment_words_serie.value_counts()\n",
    "\n",
    "\n",
    "        P_C_dado_R = 1\n",
    "        Ps_C_dado_R = []\n",
    "        for j in range(len(comment_words_list)):\n",
    "            if comment_words_list[j] not in relevant_words:\n",
    "                Ps_C_dado_R.append(Laplace(relevant_words, relevant_words_relative, irrelevant_words_relative))\n",
    "            if comment_words_list[j] == 'xiaomi':\n",
    "                continue\n",
    "            else:\n",
    "                Ps_C_dado_R.append(relevant_words_relative[j])\n",
    "        P_C_dado_R = MultiplyList(Ps_C_dado_R)\n",
    "                \n",
    "\n",
    "\n",
    "        P_C_dado_Rc = 1\n",
    "        Ps_C_dado_Rc = []\n",
    "        for j in range(len(comment_words_list)):\n",
    "            if comment_words_list[j] not in irrelevant_words:\n",
    "                Ps_C_dado_Rc.append(Laplace(irrelevant_words, irrelevant_words_relative, relevant_words_relative))\n",
    "            if comment_words_list[j] == 'xiaomi':\n",
    "                continue\n",
    "            else:\n",
    "                Ps_C_dado_Rc.append(irrelevant_words_relative[j])\n",
    "        P_C_dado_Rc = MultiplyList(Ps_C_dado_Rc)\n",
    "        \n",
    "\n",
    "        P_C = 1\n",
    "        for x in range(len(comment_words_list)):\n",
    "            if comment_words_list[x] not in all_words_relative:\n",
    "                continue\n",
    "            else:\n",
    "                P_C *= all_words_relative[comment_words_list[x]]\n",
    "\n",
    "\n",
    "        P_R = len(relevant_words) / (len(relevant_words) + len(irrelevant_words))\n",
    "\n",
    "        P_Rc = len(irrelevant_words) / (len(relevant_words) + len(irrelevant_words))\n",
    "\n",
    "        P_R_dado_C = P_R * P_C_dado_R\n",
    "\n",
    "        P_Rc_dado_C = P_Rc * P_C_dado_Rc\n",
    "\n",
    "\n",
    "        if P_R_dado_C > P_Rc_dado_C:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "\n",
    "        df2.iloc[i, 2] = result\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
