{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: _Marco Tulio Masselli Rainho Teixeira_\n",
    "\n",
    "Nome: _Talissa Gonçalves Albertini_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este classificador automático de sentimento tem o objetivo de promover uma otimização no processo de interpretação de feed back de qualquer produto no mercado, identificando características que os usuários aprovam ou reprovam, e no ambiente do Twitter, selecionando comentários que tenham uma maior probabilidade de serem relevantes à equipe que os analizará."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparação do ambiente do Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "from string import punctuation\n",
    "import nltk \n",
    "from nltk.stem import RSLPStemmer\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carregando a base de dados com os tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('xiaomi.xlsx')\n",
    "df1 = pd.read_excel(xls, 'Treinamento')\n",
    "df2 = pd.read_excel(xls, 'Teste')\n",
    "\n",
    "print(df1.head())\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 3. Tratamento do banco de dados de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Remoção de pontuação e uniformização de minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def  Cleanup(df, text_column):\n",
    "    df[text_column] = df[text_column].str.lower()\n",
    "    df[text_column] = df[text_column].str.replace(rf'[{punctuation}]', '')\n",
    "    return df\n",
    "\n",
    "print(Cleanup(df1, 'Treinamento').head(10))\n",
    "print(Cleanup(df2, 'Teste').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Divisão por relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_comments = df1[df1.Relevancia == 1] \n",
    "relevant_comments_column = relevant_comments['Treinamento']\n",
    "relevant_comments_list = relevant_comments_column.values.tolist()\n",
    "print(relevant_comments_list[0:10])\n",
    "\n",
    "irrelevant_comments = df1[df1.Relevancia == 0]\n",
    "irrelevant_comments_column = irrelevant_comments['Treinamento']\n",
    "irrelevant_comments_list = irrelevant_comments_column.values.tolist()\n",
    "#print(irrelevant_comments_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Separação de palávras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_words_raw = [word for comment in relevant_comments_list for word in comment.split()]\n",
    "print(relevant_words_raw[0:30])\n",
    "\n",
    "irrelevant_words_raw = [word for comment in irrelevant_comments_list for word in comment.split()]\n",
    "#print(irrelevant_words_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Remoção de stopwords e stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWords(list_of_words):\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    filtered = []\n",
    "    for word in list_of_words:\n",
    "        if word not in stopwords:\n",
    "            filtered.append(word)\n",
    "    return filtered\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "def Stemming(list_of_words):\n",
    "    stemmer = RSLPStemmer()\n",
    "    filtered = []\n",
    "    for word in list_of_words:\n",
    "        filtered.append(stemmer.stem(word.lower()))\n",
    "    return filtered\n",
    "\n",
    "relevant_words = Stemming(RemoveStopWords(relevant_words_raw))\n",
    "irrelevant_words = Stemming(RemoveStopWords(irrelevant_words_raw))\n",
    "\n",
    "\n",
    "#print(relevant_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Cálculo das frequências relativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_words_serie = pd.Series(relevant_words)\n",
    "relevant_words_relative = relevant_words_serie.value_counts(True)\n",
    "print(relevant_words_relative.head())\n",
    "\n",
    "irrelevant_words_serie = pd.Series(irrelevant_words)\n",
    "irrelevant_words_relative = irrelevant_words_serie.value_counts(True)\n",
    "#print(irrelevant_words_relative.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Espaço amostral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de todas as palávras\n",
    "all_words = relevant_words + irrelevant_words\n",
    "all_words[0:10]\n",
    "\n",
    "# Frequências relativas do total de palávras\n",
    "all_words_serie = pd.Series(all_words)\n",
    "all_words_relative = all_words_serie.value_counts(True)\n",
    "print(all_words_relative.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Descrição das probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eventos\n",
    "\n",
    "* R: Comentário relevante\n",
    "* Rc: Comentário irrelevante\n",
    "* C: Comentário\n",
    "\n",
    "#### Probabilidades\n",
    "\n",
    "* P_R = Probabilidade do comentário ser relevante\n",
    "* P_Rc = Probabilidade do comentario ser irrelevante\n",
    "* P_C = Probabilidade do comentário ocorrer na lingua portugueasa = propabilidade de cada palavra ocorrer na lingua portuguesa, multiplicadas entre si\n",
    "* P_C_dado_R = Probabilidade do comentário ocorrer dado que o é relevante = probabilidade de cada palavra ocorrer dado que o comentário é relevante, multiplicados entre si\n",
    "* P_C_dado_Rc = Probabilidade do comentário ocorrer dado que é irrelevante = probabilidade de cada palavra ocorrer dado que o comentário é irrelevante, multiplicados entre si\n",
    "* P_R_dado_C = Probabilidade do cometário ser relevante dado o comentário\n",
    "* P_Rc_dado_C =Probabilidade do cometário ser irrelevante dado o comentário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Funções auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Função para a suavização de Laplace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Laplace(N_words_X, N_dif_words_X, N_dif_words_Xc):\n",
    "    correction = 1/(len(N_words_X) + len(N_dif_words_X) + len(N_dif_words_Xc))\n",
    "    return correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Função multiplicadora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiplyList(List) : \n",
    "    result = 1\n",
    "    for x in List: \n",
    "         result = result * x  \n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_range = []\n",
    "for row in df2.index: \n",
    "    df2_range.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Função classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['test_result'] = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier(df):\n",
    "    for i in df2_range:\n",
    "        comment = df2.iloc[i, 1]\n",
    "\n",
    "\n",
    "        # Frequencia das palavras do comentario\n",
    "        comment_words = comment.split()\n",
    "        comment_words_list = Stemming(RemoveStopWords(comment_words))\n",
    "        comment_words_serie = pd.Series(comment_words_list)\n",
    "        comment_words_frequency = comment_words_serie.value_counts()\n",
    "\n",
    "\n",
    "        P_C_dado_R = 1\n",
    "        Ps_C_dado_R = []\n",
    "        for j in range(len(comment_words_list)):\n",
    "            if comment_words_list[j] not in relevant_words:\n",
    "                Ps_C_dado_R.append(Laplace(relevant_words, relevant_words_relative, irrelevant_words_relative))\n",
    "            if comment_words_list[j] == 'xiaomi':\n",
    "                continue\n",
    "            else:\n",
    "                Ps_C_dado_R.append(relevant_words_relative[j])\n",
    "        P_C_dado_R = MultiplyList(Ps_C_dado_R)\n",
    "                \n",
    "\n",
    "\n",
    "        P_C_dado_Rc = 1\n",
    "        Ps_C_dado_Rc = []\n",
    "        for j in range(len(comment_words_list)):\n",
    "            if comment_words_list[j] not in irrelevant_words:\n",
    "                Ps_C_dado_Rc.append(Laplace(irrelevant_words, irrelevant_words_relative, relevant_words_relative))\n",
    "            if comment_words_list[j] == 'xiaomi':\n",
    "                continue\n",
    "            else:\n",
    "                Ps_C_dado_Rc.append(irrelevant_words_relative[j])\n",
    "        P_C_dado_Rc = MultiplyList(Ps_C_dado_Rc)\n",
    "        \n",
    "\n",
    "        P_C = 1\n",
    "        for x in range(len(comment_words_list)):\n",
    "            if comment_words_list[x] not in all_words_relative:\n",
    "                continue\n",
    "            else:\n",
    "                P_C *= all_words_relative[comment_words_list[x]]\n",
    "\n",
    "\n",
    "        P_R = len(relevant_words) / (len(relevant_words) + len(irrelevant_words))\n",
    "\n",
    "        P_Rc = len(irrelevant_words) / (len(relevant_words) + len(irrelevant_words))\n",
    "\n",
    "        P_R_dado_C = P_R * P_C_dado_R\n",
    "\n",
    "        P_Rc_dado_C = P_Rc * P_C_dado_Rc\n",
    "\n",
    "\n",
    "        if P_R_dado_C > P_Rc_dado_C:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "\n",
    "        df2.iloc[i, 2] = result\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 6. Verificando a performance do classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Teste com o banco de dados Teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Análise de eficiência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verdadeiros_positivos = 0\n",
    "verdadeiros_negativos = 0\n",
    "falsos_positivos = 0\n",
    "falsos_negativos = 0\n",
    "\n",
    "for y in df2_range:\n",
    "    if (df2.iloc[y, 0] == 1) & (df2.iloc[y, 2] == 1):\n",
    "        verdadeiros_positivos +=1\n",
    "        \n",
    "    elif (df2.iloc[y, 0] == 0) & (df2.iloc[y, 2] == 0):\n",
    "        verdadeiros_negativos +=1\n",
    "    \n",
    "    elif (df2.iloc[y, 0] == 0) & (df2.iloc[y, 2] == 1):\n",
    "        falsos_positivos +=1\n",
    "        \n",
    "    else:\n",
    "        falsos_negativos +=1\n",
    "        \n",
    "print('Verdadeiros_positivos = {0}'.format(verdadeiros_positivos))\n",
    "print('Verdadeiros_negativos = {0}'.format(verdadeiros_negativos))\n",
    "print('Falsos_positivos = {0}'.format(falsos_positivos))\n",
    "print('Falsos_negativos = {0}'.format(falsos_negativos))\n",
    "\n",
    "print('Porcentagem de acertos = {0}'.format((verdadeiros_positivos + verdadeiros_negativos)*100 / len(df2_range)))\n",
    "print('Porcentagem de erros = {0}'.format((falsos_positivos + falsos_negativos)*100 / len(df2_range)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 7. Conclusão "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A performance do classificador foi abaixo da esperada, obtendo percentual de acertos de aproximadamente 55 %, sendo o número de falsos positivos maior do que o dobro de falsos negativos. Existem diversos fatores que podem influenciar os resultados, nesse caso, várias melhorias podem ser feitas, entre elas:\n",
    "\n",
    "\n",
    "- Agrupamento de palávras por critérios de morfologia e sintáse, ou seja, por similaridades entre fuções das palavras dentro da frase, uma vez que classificadores Naive Bayes não consideram a relação entre as palavras. Essa melhoria seria muito significativa se aplicada ao banco de dados antes da função Classifier e caso houvesse uma classiificação posterior de \"comentários positivos\" e \"comentários negativos\" seria ainda mais relevante. [Introduction to Syntax Analysis in Compiler Design](https://www.geeksforgeeks.org/introduction-to-syntax-analysis-in-compiler-design/). , [Types of Parsers in Compiler Design](https://www.geeksforgeeks.org/types-of-parsers-in-compiler-design/?ref=rp)\n",
    "\n",
    "- Incorporação de análise de significados de emojis, o que poderia ser feito pela substituição dos emojis por uma ou mais palavras que represetassem seu significado. Essa melhoria no classificador seria mais relevante se fosse aplicada apenas no grupo de comnetários relevantes, ou seja, em uma função após a função Classifier.  [Emoticon and Emoji in Text Mining](https://medium.com/towards-artificial-intelligence/emoticon-and-emoji-in-text-mining-7392c49f596a)\n",
    "\n",
    "- Um refinamento maior na análise das palavras individualmente, como diferenciação entre siglas e palavras comuns.\n",
    "\n",
    "- Incorporação de análise de imagens e gifs seguindo o mesmo princípio da interpretação de emojis, ou seja, substituir imagens por algumas palvras que remetam a uma ação ou sentimento e tambem aplicada no grupo de comentários relevantes. [Image Data Analysis Using Python](https://towardsdatascience.com/image-data-analysis-using-python-edddfdf128f4). , [Basic Image Data Analysis Using Python: Part 1](https://dzone.com/articles/image-data-analysis-using-numpy-amp-opencv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora o desempenho do classificador não tenha sido satisfatório, esse tipo de projeto tem um grande potencial para a otimização de pessoas e recursos em departamentos de análise de aceitação de produtos. Com as devidas melhorias esse classificador pode se tornar uma ferramenta indispensável dentro de uma empresa, proporcionando um meio de comunicação entre os desenvolvedores e os usuários de determinados produtos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
